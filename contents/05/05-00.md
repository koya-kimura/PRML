---
marp: true
paginate: true
math: katex
size: 16:9
theme: gaia
backgroundColor: white
---
## 05 : Neural Networks
### 05-00 : section introduction
---
### 第4章以前の内容について

第3章と第4章では, 回帰と分類のためのモデルについて考察した. <br> これらのモデルは基底関数 (basis function) の線形結合から成り立っており, 解析的および計算的に扱いやすいが, 次元の呪いにより実用的な適用は制限されていた.

※ 次元の呪い(Curse of Dimensionality)とは
データの次元が増加すると, データが均等に分布せず, データ点間の距離が増加する.

---
### 大規模なデータに対応するために

大規模なデータにこれらのモデルを適用する方法として, 第7章で取り上げるサポートベクトルマシン (SVM) と本章で扱う順伝播型ニューラルネットワーク(feed-forward neural network)がある. feed-forward neural network は multilayer perceptron ともいう.
通常, SVM と同じ汎化性能を持つ場合でも, multilayer perceptron の方がはるかにコンパクトで評価が迅速である. <br> このコンパクトさの代償として, ネットワーク訓練の基盤となる尤度関数はモデルパラメータの凸関数でない.

---
### feed-forward neural network について

「ニューラルネットワーク」という用語は, 生物学的システムでの情報処理の数学的表現を見つける試みに由来し (McCullochとPitts, 1943；Widrow Hoff, 1960；Rosenblatt, 1962；Rumelhart et al., 1986), 実際には非常に幅広く使用され, その多くは生物学的な妥当性に関する誇張された主張の対象となってきました.

---
### 第5章の流れ

まず, ネットワークモデルの機能形式を検討し, 基底関数の特定のパラメータ化を含めます. その後, 最大尤度フレームワーク内でネットワークパラメータを決定する問題について議論し, 非線形最適化問題の解決を必要とします.
次に, ニューラルネットワークトレーニングの正則化に関するさまざまなアプローチとそれらの関係について議論します. また, ニューラルネットワークモデルへのいくつかの拡張について考察し, 特に混合密度ネットワークとして知られる条件付き確率分布モデルの一般的なフレームワークを説明します.



